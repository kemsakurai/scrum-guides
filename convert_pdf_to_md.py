#!/usr/bin/env python3
"""
Scrum Guides PDF to Markdown Converter

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€config.jsonã§å®šç¾©ã•ã‚ŒãŸã‚¹ã‚¯ãƒ©ãƒ ã‚¬ã‚¤ãƒ‰PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€
marker-pdfã‚’ä½¿ç”¨ã—ã¦Markdownå½¢å¼ã«å¤‰æ›ã—ã¾ã™ã€‚

æ©Ÿèƒ½:
- PDFã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨Markdownå¤‰æ›
- ç”»åƒã®è‡ªå‹•æŠ½å‡ºã¨å‚ç…§ãƒ‘ã‚¹ä¿®æ­£
- Markdownã®æœ€é©åŒ–ï¼ˆç©ºè¡Œå‰Šæ¸›ã€è¡Œæœ«ç©ºç™½å‰Šé™¤ãªã©ï¼‰
- ç”»åƒå‚ç…§ã®æ¤œè¨¼
- ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã®å‡¦ç†
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½
"""

import argparse
import json
import os
import re
import shutil
import sys
import time
from pathlib import Path
from datetime import datetime
import requests
from marker.converters.pdf import PdfConverter
from marker.models import create_model_dict
from marker.output import text_from_rendered


def load_config(config_path: str = "config.json") -> dict:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {config_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {config_path} ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


def ensure_directories(config: dict) -> None:
    """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã™ã‚‹"""
    dirs = [
        config.get("output_dir", "docs"),
        config.get("image_dir", "docs/images"),
        config.get("temp_dir", "temp"),
        "backups",
    ]
    for dir_path in dirs:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
    print(f"âœ… ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ: {', '.join(dirs)}")


def download_pdf(url: str, output_path: str) -> None:
    """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
    try:
        print(f"  ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {url}")
        response = requests.get(url, timeout=60, stream=True)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        downloaded_size = 0
        
        with open(output_path, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded_size += len(chunk)
                    if total_size > 0:
                        progress = (downloaded_size / total_size) * 100
                        print(f"\r  é€²æ—: {progress:.1f}%", end="", flush=True)
        
        print()  # æ”¹è¡Œ
        file_size = os.path.getsize(output_path) / (1024 * 1024)
        print(f"  âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº† ({file_size:.2f} MB)")
    except requests.exceptions.RequestException as e:
        print(f"\n  âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        raise


def optimize_markdown_content(content: str) -> str:
    """Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æœ€é©åŒ–"""
    lines = content.split('\n')
    optimized_lines = []
    empty_line_count = 0
    
    for line in lines:
        # è¡Œæœ«ã®ç©ºç™½ã‚’å‰Šé™¤
        line = line.rstrip()
        
        # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆ/* Lines ... omitted */ãªã©ï¼‰
        if re.match(r'^\s*/\*.*\*/\s*$', line):
            continue
        
        # ç©ºã®ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
        if re.match(r'^\s*\|\s*\|.*\|\s*$', line):
            # ã™ã¹ã¦ã®ã‚»ãƒ«ãŒç©ºã®å ´åˆ
            cells = line.split('|')
            non_empty_cells = [c for c in cells if c.strip()]
            if not non_empty_cells:
                continue
        
        # ç©ºè¡Œã®ã‚«ã‚¦ãƒ³ãƒˆ
        if not line:
            empty_line_count += 1
            # æœ€å¤§2è¡Œã®ç©ºè¡Œã¾ã§è¨±å¯
            if empty_line_count <= 2:
                optimized_lines.append(line)
        else:
            empty_line_count = 0
            optimized_lines.append(line)
    
    # æœ€å¾Œã®ç©ºè¡Œã‚’å‰Šé™¤
    while optimized_lines and not optimized_lines[-1]:
        optimized_lines.pop()
    
    return '\n'.join(optimized_lines) + '\n'


def backup_markdown_file(md_path: str) -> str:
    """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
    backup_dir = Path("backups")
    backup_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = Path(md_path).name
    backup_path = backup_dir / f"{filename}.{timestamp}.bak"
    
    shutil.copy2(md_path, backup_path)
    return str(backup_path)


def optimize_markdown_file(md_path: str) -> tuple[int, int]:
    """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€é©åŒ–ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆï¼‰"""
    path = Path(md_path)
    
    if not path.exists():
        print(f"  âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {md_path}")
        return 0, 0
    
    # å…ƒã®ã‚µã‚¤ã‚ºã‚’å–å¾—
    original_size = path.stat().st_size
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ
    backup_path = backup_markdown_file(md_path)
    print(f"  ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_path}")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    with open(path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æœ€é©åŒ–
    optimized_content = optimize_markdown_content(content)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
    with open(path, 'w', encoding='utf-8') as f:
        f.write(optimized_content)
    
    # æ–°ã—ã„ã‚µã‚¤ã‚ºã‚’å–å¾—
    new_size = path.stat().st_size
    
    return original_size, new_size


def verify_images(md_path: str, image_dir: str) -> dict:
    """ç”»åƒå‚ç…§ã®æ¤œè¨¼"""
    result = {
        'file': Path(md_path).name,
        'references': [],
        'missing': [],
        'found': []
    }
    
    with open(md_path, 'r', encoding='utf-8') as f:
        content = f.read()
        image_refs = re.findall(r'!\[([^\]]*)\]\(([^)]+)\)', content)
        
        for alt, path in image_refs:
            result['references'].append((alt, path))
            
            # ç›¸å¯¾ãƒ‘ã‚¹ã‚’è§£æ±º
            full_path = Path(md_path).parent / path
            if full_path.exists():
                result['found'].append(path)
            else:
                result['missing'].append(path)
    
    return result


def convert_pdf_to_markdown(pdf_path: str, output_md_path: str, image_dir: str) -> None:
    """marker-pdfã‚’ä½¿ç”¨ã—ã¦PDFã‚’Markdownã«å¤‰æ›ã™ã‚‹"""
    try:
        print(f"  ğŸ”„ Markdownå¤‰æ›ä¸­...")
        
        # marker-pdfã®å¤‰æ›å™¨ã‚’åˆæœŸåŒ–
        converter = PdfConverter(
            artifact_dict=create_model_dict(),
        )
        
        # PDFã‚’å¤‰æ›
        rendered = converter(pdf_path)
        markdown_text, metadata, images = text_from_rendered(rendered)
        
        # Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        with open(output_md_path, "w", encoding="utf-8") as f:
            f.write(markdown_text)
        
        print(f"  âœ… Markdownä¿å­˜å®Œäº†: {output_md_path}")
        
        # ç”»åƒã‚’ä¿å­˜ã—ã€åå‰ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
        image_mapping = {}
        if images:
            print(f"  ğŸ–¼ï¸  ç”»åƒã‚’ä¿å­˜ä¸­... ({len(images)}æš)")
            Path(image_dir).mkdir(parents=True, exist_ok=True)
            
            base_name = Path(output_md_path).stem
            for idx, (img_name, img_data) in enumerate(images.items()):
                img_filename = f"{base_name}_image_{idx + 1}.png"
                img_path = os.path.join(image_dir, img_filename)
                
                # img_dataãŒPIL Imageã®å ´åˆã€bytesã«å¤‰æ›
                if hasattr(img_data, 'save'):
                    # PIL Imageã®å ´åˆ
                    img_data.save(img_path, 'PNG')
                else:
                    # bytesã®å ´åˆ
                    with open(img_path, "wb") as img_file:
                        img_file.write(img_data)
                
                # ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ: PDFå†…ã®ç”»åƒå -> ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«å
                image_mapping[img_name] = f"images/{img_filename}"
            
            print(f"  âœ… ç”»åƒä¿å­˜å®Œäº†: {len(images)}æš")
        else:
            print(f"  â„¹ï¸  ç”»åƒãªã—")
        
        # Markdownå†…ã®ç”»åƒå‚ç…§ã‚’ä¿®æ­£
        if image_mapping:
            print(f"  ğŸ”§ ç”»åƒå‚ç…§ã‚’ä¿®æ­£ä¸­...")
            with open(output_md_path, "r", encoding="utf-8") as f:
                content = f.read()
            
            # ç”»åƒå‚ç…§ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç½®æ›
            for old_name, new_path in image_mapping.items():
                pattern = r'!\[\]\(' + re.escape(old_name) + r'\)'
                replacement = f'![{old_name}]({new_path})'
                content = re.sub(pattern, replacement, content)
            
            # æ›´æ–°ã—ãŸå†…å®¹ã‚’ä¿å­˜
            with open(output_md_path, "w", encoding="utf-8") as f:
                f.write(content)
            
            print(f"  âœ… ç”»åƒå‚ç…§ä¿®æ­£å®Œäº†")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚’è¡¨ç¤º
        if metadata and isinstance(metadata, dict):
            print(f"  ğŸ“Š ãƒšãƒ¼ã‚¸æ•°: {metadata.get('page_stats', {}).get('pages', 'N/A')}")
        elif metadata:
            print(f"  ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {type(metadata)}")
        
    except Exception as e:
        print(f"  âŒ å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        raise


def format_duration(seconds: float) -> str:
    """å‡¦ç†æ™‚é–“ã‚’äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹"""
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    elif seconds < 3600:
        minutes = seconds / 60
        return f"{minutes:.1f}åˆ†"
    else:
        hours = seconds / 3600
        return f"{hours:.1f}æ™‚é–“"


def process_pdf(pdf_info: dict, config: dict, args, index: int, total: int) -> bool:
    """1ã¤ã®PDFã‚’å‡¦ç†ã™ã‚‹"""
    name = pdf_info["name"]
    url = pdf_info["url"]
    output_filename = pdf_info["output_filename"]
    
    print(f"\n{'='*70}")
    print(f"ğŸ“„ [{index}/{total}] {name}")
    print(f"{'='*70}")
    
    start_time = time.time()
    
    # ä¸€æ™‚PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    temp_pdf = os.path.join(config.get("temp_dir", "temp"), f"temp_{index}.pdf")
    
    # å‡ºåŠ›Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    output_md = os.path.join(config.get("output_dir", "docs"), output_filename)
    
    try:
        # PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        download_start = time.time()
        download_pdf(url, temp_pdf)
        download_time = time.time() - download_start
        print(f"  â±ï¸  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ™‚é–“: {format_duration(download_time)}")
        
        # Markdownã«å¤‰æ›
        convert_start = time.time()
        convert_pdf_to_markdown(temp_pdf, output_md, config.get("image_dir", "docs/images"))
        convert_time = time.time() - convert_start
        print(f"  â±ï¸  å¤‰æ›æ™‚é–“: {format_duration(convert_time)}")
        
        # Markdownã‚’æœ€é©åŒ–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§å®Ÿè¡Œã€--no-optimizeã§ç„¡åŠ¹åŒ–å¯èƒ½ï¼‰
        if not args.no_optimize:
            print(f"  ğŸ”§ Markdownæœ€é©åŒ–ä¸­...")
            optimize_start = time.time()
            original_size, new_size = optimize_markdown_file(output_md)
            optimize_time = time.time() - optimize_start
            
            if original_size > 0:
                reduction = original_size - new_size
                percentage = (reduction / original_size * 100) if original_size > 0 else 0
                print(f"  âœ… æœ€é©åŒ–å®Œäº†: {reduction:,} byteså‰Šæ¸› ({percentage:.1f}%)")
                print(f"  â±ï¸  æœ€é©åŒ–æ™‚é–“: {format_duration(optimize_time)}")
        
        # ç”»åƒå‚ç…§ã‚’æ¤œè¨¼ï¼ˆ--verifyãƒ•ãƒ©ã‚°ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆï¼‰
        if args.verify:
            print(f"  ğŸ” ç”»åƒå‚ç…§ã‚’æ¤œè¨¼ä¸­...")
            verify_result = verify_images(output_md, config.get("image_dir", "docs/images"))
            if verify_result['references']:
                print(f"  ğŸ“Š ç”»åƒå‚ç…§æ•°: {len(verify_result['references'])}æš")
                print(f"  âœ… æ¤œå‡º: {len(verify_result['found'])}æš")
                if verify_result['missing']:
                    print(f"  âš ï¸  è¦‹ã¤ã‹ã‚‰ãªã„: {len(verify_result['missing'])}æš")
                    for missing in verify_result['missing']:
                        print(f"     - {missing}")
        
        # ä¸€æ™‚PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if os.path.exists(temp_pdf):
            os.remove(temp_pdf)
            print(f"  ğŸ—‘ï¸  ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å®Œäº†")
        
        # åˆè¨ˆå‡¦ç†æ™‚é–“
        total_time = time.time() - start_time
        print(f"  â±ï¸  åˆè¨ˆå‡¦ç†æ™‚é–“: {format_duration(total_time)}")
        print(f"  âœ… å‡¦ç†å®Œäº†: {name}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ å‡¦ç†å¤±æ•—: {name}")
        print(f"  ã‚¨ãƒ©ãƒ¼è©³ç´°: {e}")
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if os.path.exists(temp_pdf):
            os.remove(temp_pdf)
        
        return False


def optimize_only_mode(config: dict):
    """æ—¢å­˜ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€é©åŒ–ã®ã¿å®Ÿè¡Œ"""
    print("ğŸ”§ Markdownæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰")
    print(f"é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    docs_dir = Path(config.get("output_dir", "docs"))
    
    if not docs_dir.exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {docs_dir} ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)
    
    md_files = sorted(docs_dir.glob('*.md'))
    
    if not md_files:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {docs_dir} ã«Markdownãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)
    
    print(f"ğŸ“š å‡¦ç†å¯¾è±¡: {len(md_files)}ä»¶ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«\n")
    
    total_original = 0
    total_new = 0
    
    for md_file in md_files:
        print(f"{'='*70}")
        print(f"ğŸ“„ {md_file.name}")
        print(f"{'='*70}")
        
        original_size, new_size = optimize_markdown_file(str(md_file))
        
        if original_size > 0:
            total_original += original_size
            total_new += new_size
            
            reduction = original_size - new_size
            percentage = (reduction / original_size * 100) if original_size > 0 else 0
            
            print(f"  å…ƒã®ã‚µã‚¤ã‚º: {original_size:,} bytes")
            print(f"  æ–°ã‚µã‚¤ã‚º  : {new_size:,} bytes")
            print(f"  å‰Šæ¸›é‡    : {reduction:,} bytes ({percentage:.1f}%)")
            print(f"  âœ… æœ€é©åŒ–å®Œäº†\n")
    
    total_reduction = total_original - total_new
    total_percentage = (total_reduction / total_original * 100) if total_original > 0 else 0
    
    print(f"{'='*70}")
    print(f"ğŸ‰ ã™ã¹ã¦ã®æœ€é©åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")
    print(f"{'='*70}")
    print(f"åˆè¨ˆå‰Šæ¸›é‡: {total_reduction:,} bytes ({total_percentage:.1f}%)")
    print(f"å…ƒã®åˆè¨ˆ  : {total_original:,} bytes")
    print(f"æ–°ã—ã„åˆè¨ˆ: {total_new:,} bytes")
    print(f"çµ‚äº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


def verify_only_mode(config: dict):
    """æ—¢å­˜ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®ç”»åƒå‚ç…§ã‚’æ¤œè¨¼ã®ã¿å®Ÿè¡Œ"""
    print("ğŸ” ç”»åƒå‚ç…§æ¤œè¨¼ãƒ¢ãƒ¼ãƒ‰")
    print(f"é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    docs_dir = Path(config.get("output_dir", "docs"))
    image_dir = config.get("image_dir", "docs/images")
    
    if not docs_dir.exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {docs_dir} ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)
    
    md_files = sorted(docs_dir.glob('*.md'))
    
    if not md_files:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {docs_dir} ã«Markdownãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)
    
    print(f"ğŸ“š æ¤œè¨¼å¯¾è±¡: {len(md_files)}ä»¶ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«\n")
    
    total_refs = 0
    total_found = 0
    total_missing = 0
    
    for md_file in md_files:
        verify_result = verify_images(str(md_file), image_dir)
        
        if verify_result['references']:
            print(f"{'='*70}")
            print(f"ğŸ“„ {verify_result['file']}")
            print(f"{'='*70}")
            
            for alt, path in verify_result['references']:
                status = "âœ…" if path in verify_result['found'] else "âŒ"
                print(f"  {status} {alt or '(no alt)'} -> {path}")
            
            total_refs += len(verify_result['references'])
            total_found += len(verify_result['found'])
            total_missing += len(verify_result['missing'])
            
            print(f"  ğŸ“Š å‚ç…§æ•°: {len(verify_result['references'])}æš "
                  f"(æ¤œå‡º: {len(verify_result['found'])}æš, "
                  f"è¦‹ã¤ã‹ã‚‰ãªã„: {len(verify_result['missing'])}æš)\n")
    
    print(f"{'='*70}")
    print(f"ğŸ‰ æ¤œè¨¼ãŒå®Œäº†ã—ã¾ã—ãŸ")
    print(f"{'='*70}")
    print(f"ç·ç”»åƒå‚ç…§æ•°: {total_refs}æš")
    print(f"âœ… æ¤œå‡º: {total_found}æš")
    if total_missing > 0:
        print(f"âŒ è¦‹ã¤ã‹ã‚‰ãªã„: {total_missing}æš")
    print(f"çµ‚äº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


def filter_pdfs(pdfs: list, args) -> list:
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã«åŸºã¥ã„ã¦PDFãƒªã‚¹ãƒˆã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
    if args.files:
        filtered = [p for p in pdfs if p["name"] in args.files]
        not_found = set(args.files) - {p["name"] for p in filtered}
        if not_found:
            print(f"âš ï¸  è­¦å‘Š: ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒconfig.jsonã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:")
            for name in not_found:
                print(f"  - {name}")
        return filtered
    elif args.versions:
        filtered = [p for p in pdfs if p["version"] in args.versions]
        not_found = set(args.versions) - {p["version"] for p in filtered}
        if not_found:
            print(f"âš ï¸  è­¦å‘Š: ä»¥ä¸‹ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒconfig.jsonã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:")
            for ver in not_found:
                print(f"  - {ver}")
        return filtered
    return pdfs


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description="Scrum Guides PDF to Markdown Converter",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # ã™ã¹ã¦ã®PDFã‚’å‡¦ç†ï¼ˆè‡ªå‹•æœ€é©åŒ–ã‚ã‚Šï¼‰
  %(prog)s
  
  # ç‰¹å®šã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†
  %(prog)s --files "Scrum Guide 2020" "Nexus Guide 2021"
  
  # ç‰¹å®šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ã¿å‡¦ç†
  %(prog)s --versions 2020 2017
  
  # æœ€é©åŒ–ãªã—ã§å‡¦ç†
  %(prog)s --no-optimize
  
  # æ—¢å­˜ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€é©åŒ–ã®ã¿
  %(prog)s --optimize-only
  
  # ç”»åƒå‚ç…§ã®æ¤œè¨¼ã®ã¿
  %(prog)s --verify-only
  
  # å‡¦ç†æ™‚ã«ç”»åƒå‚ç…§ã‚‚æ¤œè¨¼
  %(prog)s --verify
        """
    )
    
    # ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
    parser.add_argument(
        "--files", "-f",
        nargs="+",
        metavar="NAME",
        help="å‡¦ç†ã™ã‚‹PDFã®åå‰ã‚’æŒ‡å®šï¼ˆconfig.jsonã®nameãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨ä¸€è‡´ï¼‰"
    )
    
    parser.add_argument(
        "--versions", "-v",
        nargs="+",
        metavar="VERSION",
        help="å‡¦ç†ã™ã‚‹PDFã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®šï¼ˆä¾‹: 2020 2017ï¼‰"
    )
    
    # æœ€é©åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        "--no-optimize",
        action="store_true",
        help="Markdownæœ€é©åŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—"
    )
    
    parser.add_argument(
        "--optimize-only",
        action="store_true",
        help="æ—¢å­˜ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€é©åŒ–ã®ã¿å®Ÿè¡Œï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»å¤‰æ›ãªã—ï¼‰"
    )
    
    # æ¤œè¨¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        "--verify",
        action="store_true",
        help="å¤‰æ›å¾Œã«ç”»åƒå‚ç…§ã®æ•´åˆæ€§ã‚’æ¤œè¨¼"
    )
    
    parser.add_argument(
        "--verify-only",
        action="store_true",
        help="æ—¢å­˜ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®ç”»åƒå‚ç…§ã‚’æ¤œè¨¼ã®ã¿å®Ÿè¡Œ"
    )
    
    # ãã®ä»–
    parser.add_argument(
        "--config", "-c",
        default="config.json",
        metavar="PATH",
        help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: config.jsonï¼‰"
    )
    
    args = parser.parse_args()
    
    # è¨­å®šã‚’èª­ã¿è¾¼ã‚€
    config = load_config(args.config)
    
    # æœ€é©åŒ–ã®ã¿ãƒ¢ãƒ¼ãƒ‰
    if args.optimize_only:
        optimize_only_mode(config)
        return
    
    # æ¤œè¨¼ã®ã¿ãƒ¢ãƒ¼ãƒ‰
    if args.verify_only:
        verify_only_mode(config)
        return
    
    # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»å¤‰æ›ï¼‰
    print("ğŸš€ Scrum Guides PDF to Markdown Converter")
    print(f"é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    ensure_directories(config)
    
    # PDFãƒªã‚¹ãƒˆã‚’å–å¾—
    pdfs = config.get("pdfs", [])
    if not pdfs:
        print("âŒ ã‚¨ãƒ©ãƒ¼: config.jsonã«PDFãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        sys.exit(1)
    
    # PDFãƒªã‚¹ãƒˆã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    pdfs = filter_pdfs(pdfs, args)
    
    if not pdfs:
        print("âŒ ã‚¨ãƒ©ãƒ¼: å‡¦ç†å¯¾è±¡ã®PDFãŒã‚ã‚Šã¾ã›ã‚“")
        sys.exit(1)
    
    print(f"\nğŸ“š å‡¦ç†å¯¾è±¡: {len(pdfs)}ä»¶ã®PDFãƒ•ã‚¡ã‚¤ãƒ«")
    print()
    
    # å„PDFã‚’å‡¦ç†
    total_start = time.time()
    success_count = 0
    failed_count = 0
    
    for index, pdf_info in enumerate(pdfs, start=1):
        if process_pdf(pdf_info, config, args, index, len(pdfs)):
            success_count += 1
        else:
            failed_count += 1
    
    # æœ€çµ‚çµæœã‚’è¡¨ç¤º
    total_time = time.time() - total_start
    print(f"\n{'='*70}")
    print(f"ğŸ‰ ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
    print(f"{'='*70}")
    print(f"âœ… æˆåŠŸ: {success_count}ä»¶")
    if failed_count > 0:
        print(f"âŒ å¤±æ•—: {failed_count}ä»¶")
    print(f"â±ï¸  ç·å‡¦ç†æ™‚é–“: {format_duration(total_time)}")
    print(f"çµ‚äº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    temp_dir = config.get("temp_dir", "temp")
    if os.path.exists(temp_dir) and not os.listdir(temp_dir):
        os.rmdir(temp_dir)
        print(f"ğŸ—‘ï¸  ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {temp_dir}")
    
    # å¤±æ•—ãŒã‚ã£ãŸå ´åˆã¯çµ‚äº†ã‚³ãƒ¼ãƒ‰1ã‚’è¿”ã™
    if failed_count > 0:
        sys.exit(1)


if __name__ == "__main__":
    main()
